from typing import Dict, Any, Union, List, Iterator
import requests
import json
import logging
try:
    from volcenginesdkarkruntime import Ark
except ImportError as e:
    logger.error(f"Failed to import volcenginesdkarkruntime: {e}")
    Ark = None
from .llm_base import BaseLLM
from .chat_message import ChatMessage

logger = logging.getLogger(__name__)


class DouyinLLM(BaseLLM):
    """æŠ–éŸ³è±†åŒ…å¤§æ¨¡å‹å®ç°ç±» (åŸºäºç«å±±å¼•æ“ARK)"""

    def _validate_config(self) -> None:
        """éªŒè¯æŠ–éŸ³é…ç½®ä¿¡æ¯"""
        if Ark is None:
            raise ValueError("volcenginesdkarkruntimeæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install volcengine-python-sdk[ark]")
        
        required_keys = ['api_key']
        for key in required_keys:
            if key not in self.config:
                raise ValueError(f"æŠ–éŸ³è±†åŒ…é…ç½®ç¼ºå°‘å¿…è¦å‚æ•°: {key}")
            if not self.config[key]:
                raise ValueError(f"æŠ–éŸ³è±†åŒ…é…ç½®å‚æ•° {key} ä¸èƒ½ä¸ºç©º")

    def _init_client(self) -> None:
        """åˆå§‹åŒ–æŠ–éŸ³è±†åŒ…å®¢æˆ·ç«¯"""
        if Ark is None:
            raise ValueError("volcenginesdkarkruntimeæœªå®‰è£…")
            
        self.api_key = self.config['api_key']
        self.base_url = self.config.get('base_url', 'https://ark.cn-beijing.volces.com/api/v3')
        self.model = self.config.get('model', 'doubao-seed-1-6-250615')
        self.temperature = self.config.get('temperature', 0.7)
        self.max_tokens = self.config.get('max_tokens', -1)
        
        try:
            # åˆå§‹åŒ–ARKå®¢æˆ·ç«¯
            self.client = Ark(
                base_url=self.base_url,
                api_key=self.api_key
            )
            logger.info(f"è±†åŒ…LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")
        except Exception as e:
            logger.error(f"è±†åŒ…LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def chat_completion(
            self,
            messages: List[ChatMessage],
            model: str = None,
            temperature: float = None,
            max_tokens: int = None,
            stream: bool = False,
            **kwargs
    ) -> Union[str, Dict[str, Any], Iterator]:
        """
        æ‰§è¡Œè±†åŒ…å¯¹è¯
        Args:
            messages: èŠå¤©å†å²æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºdoubao-seed-1-6-250615
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            stream: æ˜¯å¦æµå¼è¾“å‡º
            **kwargs: å…¶ä»–å‚æ•°
        Returns:
            Union[str, Dict[str, Any], Iterator]: æ¨¡å‹å›å¤
        """
        try:
            # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼æˆ–ä¼ å…¥çš„å‚æ•°
            model = model or self.model
            temperature = temperature if temperature is not None else self.temperature
            max_tokens = max_tokens if max_tokens is not None else self.max_tokens
            
            if max_tokens == -1:
                max_tokens = None

            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            msg_list = []
            for msg in messages:
                msg_dict = msg.to_dict()
                # æ”¯æŒå›¾ç‰‡è¾“å…¥
                if hasattr(msg, 'images') and msg.images:
                    content = [{"type": "text", "text": msg_dict["content"]}]
                    for image in msg.images:
                        content.append({
                            "type": "image_url",
                            "image_url": {"url": image}
                        })
                    msg_dict["content"] = content
                msg_list.append(msg_dict)

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                'model': model,
                'messages': msg_list,
                'temperature': temperature,
                'stream': stream
            }

            if max_tokens:
                request_params['max_tokens'] = max_tokens
            
            request_params.update(kwargs)

            logger.info(f"ğŸ¤– å¼€å§‹è±†åŒ…å¯¹è¯ï¼Œæ¨¡å‹: {model}, æµå¼: {stream}")
            logger.debug(f"è¯·æ±‚å‚æ•°: {request_params}")

            # è°ƒç”¨ARK SDK
            if stream:
                # æµå¼è°ƒç”¨
                response = self.client.chat.completions.create(**request_params)
                return response
            else:
                # éæµå¼è°ƒç”¨
                response = self.client.chat.completions.create(**request_params)
                
                logger.debug(f"è±†åŒ…å“åº”: {response}")
                
                # è§£æå“åº”
                if response.choices and len(response.choices) > 0:
                    choice = response.choices[0]
                    if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                        content = choice.message.content
                        logger.info(f"âœ… è±†åŒ…å¯¹è¯æˆåŠŸï¼Œå›å¤é•¿åº¦: {len(content) if content else 0}")
                        return content
                    elif hasattr(choice, 'text'):
                        logger.info(f"âœ… è±†åŒ…å¯¹è¯æˆåŠŸï¼Œå›å¤é•¿åº¦: {len(choice.text) if choice.text else 0}")
                        return choice.text
                
                logger.warning("è±†åŒ…å“åº”æ ¼å¼å¼‚å¸¸ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹")
                return "æŠ±æ­‰ï¼Œè·å–å›å¤å¤±è´¥"

        except Exception as e:
            logger.error(f"âŒ è±†åŒ…LLMè°ƒç”¨å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return {
                'success': False,
                'error_msg': str(e)
            }
    
    def chat_completion_stream(
            self,
            messages: List[ChatMessage],
            model: str = None,
            temperature: float = None,
            max_tokens: int = None,
            **kwargs
    ) -> Iterator[str]:
        """
        æµå¼æ‰§è¡Œè±†åŒ…å¯¹è¯
        Args:
            messages: èŠå¤©å†å²æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            **kwargs: å…¶ä»–å‚æ•°
        Yields:
            str: æµå¼è¾“å‡ºçš„æ–‡æœ¬ç‰‡æ®µ
        """
        try:
            stream_response = self.chat_completion(
                messages=messages,
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True,
                **kwargs
            )
            
            if isinstance(stream_response, dict) and not stream_response.get('success', True):
                yield f"é”™è¯¯ï¼š{stream_response.get('error_msg', 'æœªçŸ¥é”™è¯¯')}"
                return
            
            # å¤„ç†æµå¼å“åº”
            for chunk in stream_response:
                if chunk.choices and len(chunk.choices) > 0:
                    choice = chunk.choices[0]
                    
                    # æå–å¢é‡å†…å®¹
                    delta_content = ""
                    if hasattr(choice, 'delta') and hasattr(choice.delta, 'content') and choice.delta.content:
                        delta_content = choice.delta.content
                    elif hasattr(choice, 'message') and hasattr(choice.message, 'content') and choice.message.content:
                        delta_content = choice.message.content
                    
                    if delta_content:
                        yield delta_content
                        
        except Exception as e:
            logger.error(f"è±†åŒ…LLMæµå¼è°ƒç”¨å¤±è´¥: {e}")
            yield f"é”™è¯¯ï¼š{str(e)}"
